a
# Variable names should be short, but descriptive
#Camel caps:
MyMathScore =95
#Underscore:
my_math_score=95
#Dot separated:
my.math.score=95
# If you know the name of the function or object on which you want
# help:
help(read.csv)
help('read.csv')
?read.csv
# If you do not know the name of the function or object on which you
# want help:
help.search('input')
RSiteSearch('input')
??input
# Assignment using function c()
x <- c(1, 2, 3)
c(1, 2, 3)-> x
y <- c(x, 2, x)
z<-c(1e3,100)
# Vector arithmetic
x2<- c(2,4,6)
x3<- x + x2
x4<- x-x2
x5<- x*x2
x6<- x/x2
# Generating regular sequences
seq(-5, 5, by=1) -> x
x <- seq(length=10, from=-5, by=.5)
x <- rep(x, times=5)
x <- rep(x, each=5)
# Vector Operations
x=1:6
y=2
x*y
y=c(1,10)
x*y
x/y
# Logical vectors are generated by conditions:
x<- 5>4
# missing value: NA,
z<-c(1:5,NA)
is.na(z)
# miss value: NULL
# NULL cannot exist within a vector; if used, it simply disappears
z<- c(1,NULL,3)
z
#create a numerical vector
x = 1:6
#test whether x>3, create a logical vector
x>3
x<=3
x==3
y=(x>3)
x=seq(0,2,.2)
#create a new vector from the 5th element of x
x[4]
y=x[4:]
y=x[4:length(x)]
x[c(5,6,8)]
z=2:5
x=1:10
y=(x>5)
summary(y)
x[y]
x[!y]
# Factors: Examples
country<-c("US","UK","China","India","Japan","Korea","Canada")
# convert to factor
countryf<-factor(country)
country
countryf
# convert factor back to character vector
as.character(countryf)
# convert to numeric vector
as.numeric(countryf)
as.numeric(country)
# Matrices and Data Frames
aa=1:6
dim(aa)<-c(2,3)
aa
# Create a Matrix
a<-1:5
b<-rnorm(5)
# make a matrix by column binding
c.matrix<-cbind(a,b)
# names of rows and columns
rownames(c.matrix)
colnames(c.matrix)
# Indexing for matrices
c.matrix[4,2]
b
c.matrix[1,]
a
b
c.matrix[,2]
c.matrix[c.matrix>1]
# Matrix Operations
# create a matrix with 2 columns and 3 rows
# filled with random normal values
m.normal=matrix(rnorm(6),nrow=3)
m2=m.normal*10
m2
m2[,2]=m2[,2]+50
summary(m2)
# Matrices Versus Data Frames
x=1:10
y=rnorm(10)
mat<-cbind(x,y)
class(mat[,1])
z=paste0('a',1:10)
tab<-cbind(x,y,z)
class(tab)
mode(tab[,1])
head(tab,4)
tab<-data.frame(x,y,z)
class(tab)
head(tab)
mode(tab[,1])
rownames(tab)
rownames(tab)<-paste0("row",1:10)
rownames(tab)
# Data frame columns can be refered to by name using the "dollar sign" operator $
tab$x
attach(tab)
x
# Column names can be set, which can be useful for referring to data later
colnames(tab)
colnames(tab)<-c('a','b','c')
colnames(tab)
colnames(tab)<-paste0('col',1:3)
colnames(tab)
# A list is a collection of objects that may be the same or different types.
# A data frame is a list of matched column vectors.
# Create a list
x=list(1,"y",c(2,4,6))
x
length(x)
class(x)
x[[2]]
is.list(tab)
tab[[2]]
names(tab)
# Basic Plot Functions
x=rnorm(50)
y=seq(from=0,to=100,length.out=50)
plot(x,y,xlab='x normal random',ylab='y sequence', main='plot test', pch=5,col=4)
# plot(x)
lines(x,y)
points(x,y)
# Save a png image to a file
png("my.first.plot.png",width=480,height=360)
dev.off(3)
dev.list()
dev.set(2)
# setwd()
getwd()
# boxplot, (try larger size)
x=rpois(lambda=10,50)
boxplot(x)
par(mfrow=c(1,2))
boxplot(x)
boxplot(log(x))
par(mfrow=c(1,1))
# Read Data
# Use read.table() or read.csv() to read data into R
Auto=read.csv("Auto.csv",header=T,na.strings="?")
# read data from the Internet
theURL <- "http://www.jaredlander.com/data/Tomato%20First.csv"
tomato <- read.table(file=theURL,header=TRUE, sep=",")
head(tomato)
# Probability Distributions
pnorm(2,mean=5,sd=10)
dnorm(2,mean=5,sd=10)
qnorm(.38,mean=5,sd=10)
z=rnorm(mean=5,sd=100,n=10)
# Example: Uniform Distribution
dunif(x=8,min=5,max=15)
punif(10,min=5,max=15)
qunif(.8,min=5,max=15)
runif(10,min=5,max=15)
# Example: Normal Distribution
set.seed(5)
rnorm(3,mean=10,sd=20)
rnorm(3,mean=10,sd=20)
set.seed(5)
rnorm(3,mean=10,sd=20)
# Sample Function
sample(1:40,5)
sample(c("H","T"),10,replace=T)
sample(c("success","failure"),10,replace=T,prob=c(0.8,0.2))
# Probability
x<-seq(-4,4,0.01)
plot(x,dnorm(x),type="l")
x<-0:50
plot(x,dbinom(x,size=50,prob=.33),type="h")
# Define a Function
f<-function(x){3*x^(-4)}
f(2)
# Verify whether a function is a well-defined density function
integrate(f,1,Inf)
# Simulation: Generate Random Variables Following Any Distribution
set.seed(13)
U=runif(1000)
X=(1-U)^(-1/3)
View(tomato)
setwd("~/Documents/JH_MBA/BU.510.650.33_Data_Analytics/Module3")
## Best subsect selection
library(ISLR)
names(Hitters)
Hitters2=na.omit(Hitters)
library(leaps)
install.packages("leaps")
## Best subsect selection
library(ISLR)
names(Hitters)
Hitters2=na.omit(Hitters)
library(leaps)
regfit.full=regsubsets(Salary~.,data=Hitters2,nvmax=15)
reg.summary=summary(regfit.full); reg.summary
### use different approaches: R^2, adjusted R^2, CP, BIC
names(reg.summary)
View(reg.summary)
reg.summary
reg.summary$which
reg.summary$rsq
which.max(reg.summary$adjr2)
coef(regfit.full,11)
which.min(reg.summary$cp)
which.min(reg.summary$bic)
plot(reg.summary$bic,xlab="Number of Variables",type="l")#### stepwise selection: forward or backward
regfit.fwd=regsubsets(Salary~.,data=Hitters,nvmax=19, method="forward")
summary(regfit.fwd)
regfit.bwd=regsubsets(Salary~.,data=Hitters,nvmax=19, method="backward")
summary(regfit.bwd)
coef(regfit.full,7)
coef(regfit.fwd,7)
coef(regfit.bwd,7)
which.max(reg.summary$adjr2)
coef(regfit.full,11)
regfwd_summary = summary(regfit.fwd)
which.max(regfwd_summary$adjr2)
coef(regfit.fwd, 11)
which.min(reg.summary$bic)
coef(regfit.full, 6)
regbwd_summary = summary(regfit.bwd)
which.min(regbwd_summary$bic)
coef(regfit.bwd, 8)
#### in-class exercise
library(leaps)
Auto=read.csv("Auto.csv",header=T,na.strings="?")
Auto2=na.omit(Auto)
head(Auto2)
my.auto=regsubsets(mpg~.-name, data=Auto2)
coef(my.auto,3)
my.auto2=regsubsets(mpg~.-name, data=Auto2, method="forward")
coef(my.auto2,3)
my.auto3=regsubsets(mpg~.-name, data=Auto2, method="backward")
coef(my.auto3,3)
##### LASSO
grid=10^seq(10,-2,length=100)
names(Hitters2)
## Best subsect selection
library(ISLR)
names(Hitters)
Hitters2=na.omit(Hitters)
names(Hitters2)
x=model.matrix(Salary~.,Hitters2)[,-1]
y=Hitters2$Salary
library(glmnet)
install.packages("glmnet")
#### k-fold cross-validation
library(boot) # use package boot, which has function cv.glm() to perform cross-validation
require(psych)
## Best subsect selection
library(ISLR)
names(Hitters)
Hitters2=na.omit(Hitters)
#### in-class exercise
library(leaps)
Auto=read.csv("Auto.csv",header=T,na.strings="?")
Auto2=na.omit(Auto)
head(Auto2)
my.auto=regsubsets(mpg~.-name, data=Auto2)
coef(my.auto,3)
my.auto2=regsubsets(mpg~.-name, data=Auto2, method="forward")
coef(my.auto2,3)
my.auto3=regsubsets(mpg~.-name, data=Auto2, method="backward")
coef(my.auto3,3)
##### LASSO
grid=10^seq(10,-2,length=100)
names(Hitters2)
x=model.matrix(Salary~.,Hitters2)[,-1]
y=Hitters2$Salary
library(glmnet)
ridge.mod=glmnet(x,y,alpha=0,lambda=grid)
dim(coef(ridge.mod))
ridge.mod$lambda[50]
coef(ridge.mod)[,50]
ridge.mod$lambda[60]
coef(ridge.mod)[,60]
set.seed(1)
train=sample(1:nrow(x), nrow(x)/2) # split data into two subsets
test=(-train)
y.test=y[test]
ridge.mod=glmnet(x[train,], y[train], alpha=0, lambda=grid,thresh=1e-12)
ridge.pred = predict(ridge.mod, s=4, newx=x[test,])
mean((ridge.pred - y.test)^2)
## fit a ridge regression model with a very large value of lambda
ridge.pred = predict(ridge.mod, s=1e10, newx=x[test,])
mean((ridge.pred - y.test)^2)
## compare to least squares regression/linear regression
ridge.pred = predict(ridge.mod, s=0, newx=x[test,])
mean((ridge.pred - y.test)^2)
lm(y~x, subset=train)
predict(ridge.mod, s=0, exact=T, type="coefficients")[1:20,]
## lasso fit
lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid)
plot(lasso.mod)
#### cross validation
Auto=read.csv("Auto.csv",header=T,na.strings="?")
Auto2=na.omit(Auto)
library(ISLR)
set.seed(1) ## generate same random variables
train = sample(392,196) ## divide into two equal subsets
lm.fit = lm(mpg~horsepower, data=Auto2, subset=train)
attach(Auto2)
mean((mpg - predict(lm.fit, Auto2))[-train]^2) # obtain estimated test MSE
lm.fit2 = lm(mpg~poly(horsepower, 2), data=Auto2, subset=train)
summary(lm.fit2)
mean((mpg - predict(lm.fit2, Auto2))[-train]^2)
lm.fit3 = lm(mpg~poly(horsepower, 3), data=Auto2, subset=train)
#summary(lm.fit3)
mean((mpg - predict(lm.fit3, Auto2))[-train]^2)
## different training sets give different results
set.seed(2)
train = sample(392,196)
lm.fit = lm(mpg~horsepower, data=Auto2, subset=train)
mean((mpg - predict(lm.fit, Auto2))[-train]^2)
lm.fit2 = lm(mpg~poly(horsepower, 2), data=Auto2, subset=train)
mean((mpg - predict(lm.fit2, Auto2))[-train]^2)
lm.fit3 = lm(mpg~poly(horsepower, 3), data=Auto2, subset=train)
mean((mpg - predict(lm.fit3, Auto2))[-train]^2)
#### k-fold cross-validation
library(boot) # use package boot, which has function cv.glm() to perform cross-validation
set.seed(17)
glm.fit=glm(mpg~poly(horsepower,2), data=Auto2)
my.cv = cv.glm(Auto2, glm.fit, K=10)
summary(my.cv) ## my.cv$delta[1] is the cross-validation estimate
cv.error.10=rep(0,10)
for (i in 1:10)
{
glm.fit=glm(mpg~poly(horsepower,i), data=Auto2)
cv.error.10[i] = cv.glm(Auto2, glm.fit, K=10)$delta[1]
}
cv.error.10
plot(cv.error.10, type="b")
?nvmax
?nvmax=15
Auto=read.csv("Auto.csv",header=T,na.strings="?")
View(Auto)
sum(is.na(Auto))
Auto2=na.omit(Auto)
View(grid)
names(Hitters)
library(ISLR)
sum(is.na(Hitters))
regfit.full=regsubsets(Salary~.,data=Hitters2,nvmax=15)
summary(regfit.full)
View(grid)
which.min(ridge.mod)
require(psych)
Auto2=Auto[-c(10:85),]
describe(Auto2)
Auto2=Auto[-c(25:115),]
describe(Auto2)
GMAT=c(560,540,520,580,520,620,660,630,550,550,600,537,610,570,590,650)
GPA=c(3.2,3.44,3.7,3.1,3.0,4.0,3.38,3.83,2.67,2.75,2.33,3.75,3.85,3.30,3.50,3.65)
mod2=lm(GPA~GMAT); summary(mod2)
predict(mod2,  data.frame(GMAT=580))
set.seed(150)
x=rnorm(150)
Error=rnorm(150,0,0.2)
y=-1.5+0.8 * x + Error
mod3=lm(y~x);summary(mod3)
mod3$coefficients
predict(mod3, newdata=data.frame(x=1.0), interval="prediction")
cv.error.10
which.min(cv.error.10)
Auto <- read.csv(“Auto.csv”, na.strings=”?”), summary(Auto)
Auto <- read.csv(“Auto.csv”, na.strings=”?”)
Auto <- read.csv('Auto.csv', na.strings=”?”)
Auto <- read.csv('Auto.csv', na.strings='?')
summary(Auto)
View(Auto)
require(psych)
describe(Auto)
describe(Auto)$min
q2 = data.frame(cbind(describe(Auto)$min, describe(Auto)$max, describe(Auto)$median)
q2 = data.frame(cbind(describe(Auto)$min, describe(Auto)$max, describe(Auto)$median))
View(q2)
View(q2)
Auto.columns
rownames(describe(Auto))
columnnames(q2)
colnames(q2)
q2 = data.frame(cbind(rownames(describe(Auto)), describe(Auto)$min, describe(Auto)$max, describe(Auto)$median))
View(q2)
colnames(q2) = c("Variable", "Min", "Max", "Median")
q2
# Questoin 3
describe(Auto)
d_auto = describe(Auto)
q2 = data.frame(cbind(rownames(d_auto), d_auto$min, d_auto$max, d_auto$median))
colnames(q2) = c("Variable", "Min", "Max", "Median")
q2
# Questoin 3
q3 = data.frame(cbind(rownames(d_auto), d_auto$mean, d_auto$sd)
colnames(q3) = c("Variable", "Mean", "Std")
# Questoin 3
q3 = data.frame(cbind(rownames(d_auto), d_auto$mean, d_auto$sd)
q3
# Questoin 3
q3 = data.frame(cbind(rownames(d_auto), d_auto$mean, d_auto$sd))
colnames(q3) = c("Variable", "Mean", "Std")
q3
# Question 4
Auto2 <- Auto[-25]
# Question 4
Auto2 <- Auto[-c(25, 115),]
# Question 4
Auto2 <- Auto[-c(25:115),]
# Question 4
Auto2 <- Auto[-c(25:26),]
# Question 4
Auto2 <- Auto[-c(25:115),]
d_auto2 = describe(Auto2)
da2 = describe(Auto2)
q4 = data.frame(cbind(rownames(da2), da2$min, da2$max, da2$median, da2$mean, da2$sd))
colnames(q4) = c("Variable", "Min", "Max", "Median", "Mean", "Std")
q4
# Question 5
regfit_full=regsubsets(mpg~.,data=Auto)
# Question 5
Auto3 <- Auto[, -name]
# Question 5
Auto3 <- Auto[, -'name']
# Question 5
Auto3 <- Auto[, -c('name')]
# Question 5
Auto3 <- Auto[, !c('name')]
# Question 5
Auto3 <- Auto[, !(names(Auto) %in% c('name')]
# Question 5
Auto3 <- Auto$name <- NULL
# Question 5
Auto3 <- Auto
Auto3$name <- NULL
View(Auto3)
View(Auto3)
regfit_full=regsubsets(mpg~.,data=Auto3)
2**8
2**7
View(regfit_full)
reg_summary = summary(regfit_full)
View(reg_summary)
# Question 1
Auto <- read.csv('Auto.csv', na.strings='?')
summary(Auto)
# Question 5
Auto3 <- Auto
Auto3$name <- NULL
regfit_fwd=regsubsets(mpg~.,data=Auto3, method="forward")
reg_summary = summary(regfit_fwd)
View(reg_summary)
reg_summary$which
reg_summary[7]
View(regfit_fwd)
full_model <- lm(mpg ~ ., data = Auto3)
summary(full_model)
plot(reg_summary$bic,xlab="Number of Variables",type="l")
# Question 6
x <- c(560,540,520,580,520,620,660,630,550,550,600,537,610,570,590,650)
y <- c(3.2,3.44,3.7,3.1,3,4,3.38,3.83,2.67,2.75,2.33,3.75,3.85,3.3,3.5,3.65)
data6 = data.frame(c(x y))
data6 = data.frame(cbind(x y))
data6 <- data.frame(cbind(x y))
data6 <- data.frame(cbind(x,y))
View(data6)
# Question 6
gmat <- c(560,540,520,580,520,620,660,630,550,550,600,537,610,570,590,650)
gpa <- c(3.2,3.44,3.7,3.1,3,4,3.38,3.83,2.67,2.75,2.33,3.75,3.85,3.3,3.5,3.65)
data6 <- data.frame(cbind(gmat, gpa))
View(data6)
lm6 <- lm(gpa ~ gmat, data=data6)
summary(lm6)
predict(lm6, data.frame(gmat=580))
# Question 9
set.seed(0) # For reproducability
x <- rnorm(150)
error <- rnorm(150, 0, .2)
y = -1.5 + 0.8*x + error
lm9 <- lm(y~x)
summary(lm9)
# Question 10
confint(lm9)
predict(lm9, 1, interval="prediction")
predict(lm9, x=1, interval="prediction")
predict(lm9, data.frame(x=1), interval="prediction")
